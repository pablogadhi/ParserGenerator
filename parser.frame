/*----------------------------------------------------------------------
parser.h Specification
-----------------------------------------------------------------------*/

-->begin
#ifndef PARSER_H
#define PARSER_H

#include "scanner.h"

class Production
{
  private:
    string p_name;
    string p_attributes;
    vector<Token<string>> p_body;
    unordered_map<int, string> p_sem_actions;
    unordered_map<int, string> p_ident_attr;

  public:
    Production(string, string, vector<Token<string>>, unordered_map<int, string>, unordered_map<int, string>);
    Production();
    ~Production();
    string name();
    string attr();
    vector<Token<string>> &body();
    unordered_map<int, string> sem_actions();
    unordered_map<int, string> ident_attr();
};

class Parser
{
  private:
    Scanner &scanner;
    Token<string> current_token;
    vector<Token<string>> token_list;
    string new_compiler_name;
    SymbolTable new_table;
    unordered_map<string, pair<vector<Token<Set<char>>>, bool>> token_regex_map;
    string start_s_name;
    vector<Production> productions;
    unordered_map<string, int> production_indices;
    unordered_map<string, Set<string>> first_pos;
    unordered_map<string, Set<string>> follow_pos;
    vector<Error> syntactic_errors;
    vector<Token<string>> error_fixes;
    vector<Token<string>> watched_tokens;

  public:
    Parser(Scanner &);
    ~Parser();
    void parse();
    void get();
    Token<string> look_ahead();
    Token<string> last_token();
    void expect(string);
    bool soft_expect(string);
    string compiler_name();
    bool is_non_terminal(Token<string>);
-->prod_declarations
    void syn_error(string, string message = "");
    void fix_syn_error(string);
};

#endif
-->implementation

/*----------------------------------------------------------------------
parser.cpp Specification
-----------------------------------------------------------------------*/

-->begin
#include "parser.h"
#include "utils.h"
#include <iostream>

string ident_str(string str, int num)
{
    string identation = string(num, ' ');
    string result = "", str_copy = str;
    size_t pos = str.find("\n");

    do
    {
        auto sub_str = str_copy.substr(0, pos);
        result += identation + sub_str;
        str_copy.erase(0, pos + 1);
        if (str_copy.size() < str.size())
        {
            result += "\n";
        }
    } while ((pos = str_copy.find("\n")) != string::npos);

    return result;
}

int find_token_in_prod(Production prod, Token<string> token, int offset = 0)
{
    for (int i = offset; i < prod.body().size(); i++)
    {
        if (prod.body()[i].name() == token.name())
        {
            return i;
        }
    }
    return -1;
}

Production::Production(string name, string attr, vector<Token<string>> body, unordered_map<int, string> sem_actions,
                       unordered_map<int, string> ident_attr)
    : p_name(name), p_attributes(attr), p_body(body), p_sem_actions(sem_actions), p_ident_attr(ident_attr)
{
}

Production::Production()
{
}

Production::~Production()
{
}

string Production::name()
{
    return p_name;
}

string Production::attr()
{
    return p_attributes;
}

vector<Token<string>> &Production::body()
{
    return p_body;
}

unordered_map<int, string> Production::sem_actions()
{
    return p_sem_actions;
}

unordered_map<int, string> Production::ident_attr()
{
    return p_ident_attr;
}

Parser::Parser(Scanner &sc) : scanner(sc)
{
    scanner.get_finder().draw_machine("Scanner_DFA");
    scanner.scan();
}

Parser::~Parser()
{
}

void Parser::get()
{
    if (!error_fixes.empty())
    {
        current_token = error_fixes.back();
        error_fixes.pop_back();
        token_list.push_back(current_token);
    }
    else if (!watched_tokens.empty())
    {
        current_token = watched_tokens.back();
        watched_tokens.pop_back();
        token_list.push_back(current_token);
    }
    else
    {
        auto token_to_be = scanner.scan();
        if (token_to_be.name() != "<ERROR>")
        {
            current_token = token_to_be;
            token_list.push_back(current_token);
        }
        else
        {
            get();
        }
    }
}

Token<string> Parser::look_ahead()
{
    if (watched_tokens.empty())
    {
        return scanner.look_ahead();
    }
    else
    {
        return watched_tokens.back();
    }
}

Token<string> Parser::last_token()
{
    return *(token_list.end() - 2);
}

void Parser::expect(string str)
{
    // Refactor this code to be more efficient
    if (current_token.name() == str)
    {
        return;
    }

    while (true)
    {
        get();
        if (current_token.name() == str || current_token.name() == "<EOF>")
        {
            break;
        }
        else
        {
            syn_error(str);
        }
    }
}

bool Parser::soft_expect(string str)
{
    get();
    return current_token.name() == str;
}

string Parser::compiler_name()
{
    return new_compiler_name;
}

bool Parser::is_non_terminal(Token<string> token)
{
    return token.name() == "ident" && token_regex_map.find(token.value()) == token_regex_map.end();
}

-->prod_implementations

void Parser::parse()
{
-->first_prod
}

void Parser::syn_error(string token_name, string message)
{
    auto prev_token = last_token();
    string error_str = "\nSyntatic error found after (" + prev_token.name() + ", " + prev_token.value() + ")\n";
    if (message == "")
    {
        error_str += "Expected token: " + token_name + "\n" + "Found token with name: " + current_token.name() +
                     ", and value: " + current_token.value() + "\n\n";
    }
    else
    {
        error_str += message + "\n\n";
    }
    cout << error_str;
    auto error = Error(error_str, SYNTACTIC_ERROR);
    syntactic_errors.push_back(error);
    fix_syn_error(token_name);
}

void Parser::fix_syn_error(string token_name)
{
    if (look_ahead().name() != token_name)
    {
        unordered_map<string, string>::iterator keyword_itr;
        if (token_name.size() == 1)
        {
            error_fixes.push_back(Token<string>(token_name, token_name));
            watched_tokens.push_back(current_token);
            token_list.pop_back();
        }
        else if ((keyword_itr = scanner.symbols().keywords().find(token_name)) != scanner.symbols().keywords().end())
        {
            error_fixes.push_back(Token<string>((*keyword_itr).second, (*keyword_itr).second));
            watched_tokens.push_back(current_token);
            token_list.pop_back();
        }
    }
}
-->end